

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Web Scraping, Part 2 &mdash; Python Beginners  documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
        <script type="text/javascript" src="_static/language_data.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Web Scraping, Part 3" href="scraping3.html" />
    <link rel="prev" title="Web Scraping Intro" href="scraping.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> Python Beginners
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="learn_python.html">Starting Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="functions.html">Functions in Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="lists.html">Working with Lists</a></li>
<li class="toctree-l1"><a class="reference internal" href="working_with_files.html">Reading and Writing Files</a></li>
<li class="toctree-l1"><a class="reference internal" href="scraping.html">Web Scraping Intro</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Web Scraping, Part 2</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#using-select-instead-of-find-or-find-all">Using <code class="docutils literal notranslate"><span class="pre">select()</span></code> instead of <code class="docutils literal notranslate"><span class="pre">find()</span></code> or <code class="docutils literal notranslate"><span class="pre">find_all()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#working-with-lists-of-tag-objects">Working with lists of Tag objects</a></li>
<li class="toctree-l2"><a class="reference internal" href="#finding-inside-a-tag-object">Finding inside a Tag object</a></li>
<li class="toctree-l2"><a class="reference internal" href="#moving-from-page-to-page-while-scraping">Moving from page to page while scraping</a></li>
<li class="toctree-l2"><a class="reference internal" href="#harvesting-multiple-urls-from-one-page">Harvesting multiple URLs from one page</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrape-multiple-pages-with-one-script">Scrape multiple pages with one script</a></li>
<li class="toctree-l2"><a class="reference internal" href="#moving-onward">Moving onward</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="scraping3.html">Web Scraping, Part 3</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Python Beginners</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Web Scraping, Part 2</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/scraping2.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="web-scraping-part-2">
<h1>Web Scraping, Part 2<a class="headerlink" href="#web-scraping-part-2" title="Permalink to this headline">¶</a></h1>
<p>You have installed <strong>BeautifulSoup</strong> (bs4) and tried some basic scraping.</p>
<p>If you have not yet installed the <a class="reference external" href="https://requests.readthedocs.io/en/master/">Requests</a> module, do it now (in your virtual environment).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">requests</span>
</pre></div>
</div>
<p>If you have not made a virtual environment yet, see <a class="reference external" href="http://bit.ly/install-python3-jupyter">these instructions</a>.</p>
<p><a class="reference external" href="https://github.com/macloo/python-adv-web-apps/tree/master/python_code_examples/scraping">The code for this chapter is here.</a></p>
<div class="section" id="using-select-instead-of-find-or-find-all">
<h2>Using <code class="docutils literal notranslate"><span class="pre">select()</span></code> instead of <code class="docutils literal notranslate"><span class="pre">find()</span></code> or <code class="docutils literal notranslate"><span class="pre">find_all()</span></code><a class="headerlink" href="#using-select-instead-of-find-or-find-all" title="Permalink to this headline">¶</a></h2>
<p>In <a class="reference external" href="scraping.html">the previous section</a> we covered several commonly used commands for scraping with BeautifulSoup:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">soup</span><span class="o">.</span><span class="n">h1</span><span class="o">.</span><span class="n">text</span>
<span class="n">soup</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span> <span class="s2">&quot;td&quot;</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="s2">&quot;city&quot;</span> <span class="p">)</span>
<span class="n">soup</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s2">&quot;img&quot;</span><span class="p">)</span>
<span class="n">soup</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="s2">&quot;call&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>In chapter 12 of <a class="reference external" href="https://automatetheboringstuff.com/">Automate the Boring Stuff with Python</a> (second edition), the author covers another command, the <code class="docutils literal notranslate"><span class="pre">select()</span></code> method. More info: <a class="reference external" href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/#css-selectors">Read the docs</a>.</p>
<p>This method might hold special appeal to people used to working with JavaScript, because the syntax for targeting HTML elements — inside the parentheses of <code class="docutils literal notranslate"><span class="pre">select()</span></code> — follows the same syntax as this commonly used JavaScript method:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">document</span><span class="o">.</span><span class="n">querySelectorAll</span><span class="p">()</span>
</pre></div>
</div>
<p>So instead of <code class="docutils literal notranslate"><span class="pre">(</span> <span class="pre">&quot;td&quot;,</span> <span class="pre">class_=&quot;city&quot;</span> <span class="pre">)</span></code>, we would write <code class="docutils literal notranslate"><span class="pre">(</span> <span class="pre">&quot;td.city&quot;</span> <span class="pre">)</span></code>, and instead of <code class="docutils literal notranslate"><span class="pre">(id=&quot;call&quot;)</span></code>, we would write <code class="docutils literal notranslate"><span class="pre">(&quot;#call&quot;)</span></code>.</p>
<p>Note that <code class="docutils literal notranslate"><span class="pre">select()</span></code> <em>always</em> returns a list, even when only one item is found.</p>
<p>Be mindful that the way you write out what you’re looking for depends on whether you are calling <code class="docutils literal notranslate"><span class="pre">select()</span></code> or you are calling <code class="docutils literal notranslate"><span class="pre">find()</span></code> or <code class="docutils literal notranslate"><span class="pre">find_all()</span></code>. You’ll get errors if you mix up the syntax.</p>
</div>
<div class="section" id="working-with-lists-of-tag-objects">
<h2>Working with lists of Tag objects<a class="headerlink" href="#working-with-lists-of-tag-objects" title="Permalink to this headline">¶</a></h2>
<p>Both <code class="docutils literal notranslate"><span class="pre">find_all()</span></code> and <code class="docutils literal notranslate"><span class="pre">select()</span></code> always return a Python list. Each item in the list is a BeautifulSoup <strong>Tag object.</strong> You can access any list item using its index — just as you would with any normal Python list.</p>
<p>Try this code in the Python shell:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>
<span class="kn">import</span> <span class="nn">requests</span>
<span class="n">url</span> <span class="o">=</span> <span class="s2">&quot;https://weimergeeks.com/examples/scraping/example1.html&quot;</span>
<span class="n">page</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
<span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">page</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="s1">&#39;html.parser&#39;</span><span class="p">)</span>
<span class="n">images</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s1">&#39;img&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
</pre></div>
</div>
<p>You’ll see that you have a Python <strong>list</strong> of IMG elements.</p>
<p>You can call <code class="docutils literal notranslate"><span class="pre">.get_text()</span></code> or <code class="docutils literal notranslate"><span class="pre">.text</span></code> on a Tag object to get only the text inside the element. To get the text from <em>just one</em> Tag object in a list, use its <strong>list index</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cities</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s1">&#39;td.city&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cities</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cities</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>
</pre></div>
</div>
<p>To get the text from <em>all the items</em> in the list, you need a for-loop:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">city</span> <span class="ow">in</span> <span class="n">cities</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">city</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>
</pre></div>
</div>
<p>If an element has <strong>attributes,</strong> you can get a Python <strong>dictionary</strong> containing all of them — again, use an index to see just one item from the list:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">images</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s1">&#39;img&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span> <span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">attrs</span> <span class="p">)</span>
</pre></div>
</div>
<p>Example, running the commands above in the Python shell:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span> <span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="p">)</span>
<span class="go">&lt;img alt=&quot;thumbnail&quot; src=&quot;images/thumbnails/park_structures.jpg&quot;/&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span> <span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">attrs</span> <span class="p">)</span>
<span class="go">{&#39;src&#39;: &#39;images/thumbnails/park_structures.jpg&#39;, &#39;alt&#39;: &#39;thumbnail&#39;}</span>
</pre></div>
</div>
<p>To get a particular attribute for all the IMG elements, you need a for-loop:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">image</span> <span class="ow">in</span> <span class="n">images</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span> <span class="n">image</span><span class="o">.</span><span class="n">attrs</span><span class="p">[</span><span class="s1">&#39;src&#39;</span><span class="p">]</span> <span class="p">)</span>
</pre></div>
</div>
<p>Again, here’s how that would run in the Python shell:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">image</span> <span class="ow">in</span> <span class="n">images</span><span class="p">:</span>
<span class="gp">... </span>  <span class="nb">print</span><span class="p">(</span> <span class="n">image</span><span class="o">.</span><span class="n">attrs</span><span class="p">[</span><span class="s1">&#39;src&#39;</span><span class="p">]</span> <span class="p">)</span>
<span class="gp">...</span>
<span class="go">images/thumbnails/park_structures.jpg</span>
<span class="go">images/thumbnails/building.jpg</span>
<span class="go">images/thumbnails/mosque.jpg</span>
<span class="go">images/thumbnails/turrets.jpg</span>
<span class="go">images/thumbnails/russia.jpg</span>
<span class="go">&gt;&gt;&gt;</span>
</pre></div>
</div>
<p>View the example web page to get a clear idea of where those attributes came from:</p>
<p><a class="reference external" href="https://weimergeeks.com/examples/scraping/example1.html">https://weimergeeks.com/examples/scraping/example1.html</a></p>
<p>Another way to get a particular attribute from a Tag object is with <code class="docutils literal notranslate"><span class="pre">.get()</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">image</span> <span class="ow">in</span> <span class="n">images</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span> <span class="n">image</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;src&#39;</span><span class="p">)</span> <span class="p">)</span>
</pre></div>
</div>
<p>As you see, there are various ways to do the same thing with BeautifulSoup. If you find it confusing, choose one way and stick with it.</p>
<p>When in doubt, refer to the <a class="reference external" href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/">BeautifulSoup documentation</a> — it’s all on one page, so search it with Command-F.</p>
</div>
<div class="section" id="finding-inside-a-tag-object">
<h2>Finding inside a Tag object<a class="headerlink" href="#finding-inside-a-tag-object" title="Permalink to this headline">¶</a></h2>
<p>The methods <code class="docutils literal notranslate"><span class="pre">find()</span></code>, <code class="docutils literal notranslate"><span class="pre">find_all()</span></code>, and <code class="docutils literal notranslate"><span class="pre">select()</span></code> work on Tag objects as well as BeautifulSoup objects (<a class="reference external" href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/#kinds-of-objects">types of objects are covered here</a>). Here is an example:</p>
<div class="literal-block-wrapper docutils container" id="id4">
<div class="code-block-caption"><span class="caption-text">../python_code_examples/scraping/table_scrape.py</span><a class="headerlink" href="#id4" title="Permalink to this code">¶</a></div>
<div class="highlight-default notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21</pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>
<span class="kn">import</span> <span class="nn">requests</span>

<span class="n">url</span> <span class="o">=</span> <span class="s2">&quot;https://en.wikipedia.org/wiki/List_of_Scottish_monarchs&quot;</span>
<span class="n">page</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
<span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">page</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="s1">&#39;html.parser&#39;</span><span class="p">)</span>

<span class="c1"># get the first table in the article</span>
<span class="n">table</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">find</span><span class="p">(</span> <span class="s1">&#39;table&#39;</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="s1">&#39;wikitable&#39;</span> <span class="p">)</span>

<span class="c1"># get a list of all rows in that table</span>
<span class="n">rows</span> <span class="o">=</span> <span class="n">table</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s1">&#39;tr&#39;</span><span class="p">)</span>

<span class="c1"># loop over all rows, get all cells</span>
<span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">rows</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">cells</span> <span class="o">=</span> <span class="n">row</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s1">&#39;td&#39;</span><span class="p">)</span>
        <span class="c1"># print contents of the second cell in the row</span>
        <span class="nb">print</span><span class="p">(</span> <span class="n">cells</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">text</span> <span class="p">)</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="k">pass</span>
</pre></div>
</td></tr></table></div>
</div>
<p>Once we’ve got <code class="docutils literal notranslate"><span class="pre">table</span></code> out of <code class="docutils literal notranslate"><span class="pre">soup</span></code> (line 9 above), we can go on to find elements inside the Tag object <code class="docutils literal notranslate"><span class="pre">table</span></code>. First we get a list of all rows (line 12). Then we can loop over the list of row objects (starting on line 15) and make a list of all table cells in each row (line 17). From that list, we can extract the contents of one or more cells. In the for-loop, by printing <code class="docutils literal notranslate"><span class="pre">cells[1].text</span></code> (line 19), we will see a list of all Scottish monarchs in the first table on the page.</p>
<p>It’s as if we are taking apart a set of nested boxes. We go inside the table to get the rows. We go inside a row to get its cells.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Using <code class="docutils literal notranslate"><span class="pre">try</span></code> / <code class="docutils literal notranslate"><span class="pre">except</span></code> in the script above enables us to skip over the header row of the table, where the HTML tags are <code class="docutils literal notranslate"><span class="pre">th</span></code> instead of <code class="docutils literal notranslate"><span class="pre">td</span></code>.</p>
</div>
<p>Since <a class="reference external" href="https://en.wikipedia.org/wiki/List_of_Scottish_monarchs">the Scottish monarchs page</a> has multiple tables, the code above should be modified to get them all:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tables</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span> <span class="s1">&#39;table&#39;</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="s1">&#39;wikitable&#39;</span> <span class="p">)</span>
</pre></div>
</div>
<p>And then we will need to loop through the tables:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">table</span> <span class="ow">in</span> <span class="n">tables</span><span class="p">:</span>
    <span class="n">rows</span> <span class="o">=</span> <span class="n">table</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s1">&#39;tr&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">rows</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">cells</span> <span class="o">=</span> <span class="n">row</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s1">&#39;td&#39;</span><span class="p">)</span>
            <span class="c1"># print contents of the second cell in the row</span>
            <span class="nb">print</span><span class="p">(</span> <span class="n">cells</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">text</span> <span class="p">)</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="k">pass</span>
</pre></div>
</div>
<p>Our set of nested boxes actually begins with the page. Inside the page are several tables. Inside each table, we find rows, and inside each row, we find cells. Inside the second cell in each row, we find the name of a king.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The revised script will not work perfectly on <a class="reference external" href="https://en.wikipedia.org/wiki/List_of_Scottish_monarchs">the Scottish monarchs page</a> because the tables in that page are not formatted consistently. The first table on the page has the monarch’s name in the second column, but the other tables have it in the <em>first</em> column.</p>
</div>
</div>
<div class="section" id="moving-from-page-to-page-while-scraping">
<h2>Moving from page to page while scraping<a class="headerlink" href="#moving-from-page-to-page-while-scraping" title="Permalink to this headline">¶</a></h2>
<p>In chapter 12 of <a class="reference external" href="https://automatetheboringstuff.com/">Automate the Boring Stuff with Python</a> (second edition), Sweigart provides a script to scrape the XKCD comics website (“Project: Downloading All XKCD Comics”). The code in step 4, which is part of a longer while-loop, gets the URL from an element on the page that links to the previous comic. In this way, the script <strong>starts on the home page</strong> of the site, downloads one comic, and then <strong>moves to the previous day’s comic page</strong> and downloads the comic there. The script repeats this, moving to the previous page each time, until all comics have been downloaded.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method is often exactly what you need to scrape the data that you want.</p>
</div>
<p>The trick is to determine exactly <strong>how to get the URL</strong> that leads to the next page to be scraped.</p>
<p>In the case of the XKCD site, this code works:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">prevLink</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s1">&#39;a[rel=&quot;prev&quot;]&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;https://xkcd.com&#39;</span> <span class="o">+</span> <span class="n">prevLink</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;href&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>The code <code class="docutils literal notranslate"><span class="pre">select('a[rel=&quot;prev&quot;]')</span></code> gets all <code class="docutils literal notranslate"><span class="pre">a</span></code> elements on the page that contain the attribute <code class="docutils literal notranslate"><span class="pre">rel</span></code> with the value <code class="docutils literal notranslate"><span class="pre">&quot;prev&quot;</span></code> — that is, <code class="docutils literal notranslate"><span class="pre">rel=&quot;prev&quot;</span></code>. This code returns a <strong>list,</strong> so it’s necessary to use the list index <code class="docutils literal notranslate"><span class="pre">[0]</span></code> to get the first <strong>list item.</strong></p>
<p>The next line extracts the <em>value</em> of the <code class="docutils literal notranslate"><span class="pre">href</span></code> attribute from that A element and concatenates it with the base URL, <code class="docutils literal notranslate"><span class="pre">https://xkcd.com</span></code>.</p>
<p>If you inspect the HTML on any XKCD page with Developer Tools, you can find this A element.</p>
<div class="figure align-default">
<a class="reference internal image-reference" href="_images/xkcd_prev_button.png"><img alt="Developer Tools and an XKCD web page screenshot" src="_images/xkcd_prev_button.png" style="width: 455.0px; height: 259.0px;" /></a>
</div>
<p>To understand this code better, you can run it in the Python shell. Here I have started on the page at <a class="reference external" href="https://xkcd.com/2260/">https://xkcd.com/2260/</a> —</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">requests</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;https://xkcd.com/2260/&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">page</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">page</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="s1">&#39;html.parser&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>I am not starting at the home page and I am not looping, because I want to provide a simple demonstration of what the code is getting for us.</p>
</div>
<p>Then I continued with the code to get only the “Prev” code from that one page:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">prevLink</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s1">&#39;a[rel=&quot;prev&quot;]&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">prevLink</span><span class="p">)</span>
<span class="go">&lt;a accesskey=&quot;p&quot; href=&quot;/2259/&quot; rel=&quot;prev&quot;&gt;&amp;lt; Prev&lt;/a&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span> <span class="n">prevLink</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;href&#39;</span><span class="p">)</span> <span class="p">)</span>
<span class="go">/2259/</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;https://xkcd.com&#39;</span> <span class="o">+</span> <span class="n">prevLink</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;href&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
<span class="go">https://xkcd.com/2259/</span>
<span class="go">&gt;&gt;&gt;</span>
</pre></div>
</div>
<p>Above, I have <strong>printed</strong> three things — <code class="docutils literal notranslate"><span class="pre">prevLink</span></code>, <code class="docutils literal notranslate"><span class="pre">prevLink.get('href')</span></code> and <code class="docutils literal notranslate"><span class="pre">url</span></code> — so I can see exactly what is being extracted and used.</p>
<p>In the complete script in chapter 12, once the script has that last URL, the while-loop restarts. It opens that page — <a class="reference external" href="https://xkcd.com/2259/">https://xkcd.com/2259/</a> — and downloads the comic from it.</p>
<p>This practice of <strong>printing the value each time</strong> is a way of testing your code as you go — to make sure you are getting what you intend to get. If you have an error, then you must modify the line and print it again, and repeat until that line of code gets what you want.</p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>You must understand that every website is different, so probably no other website in the world has the same HTML as the XKCD website. However, many websites do have Previous and Next buttons. It is necessary to <strong>inspect</strong> the HTML and determine how to extract the next- or previous-page URL (or partial URL) from the HTML on the button.</p>
</div>
<p><strong>Some websites use JavaScript</strong> to activate their Previous and Next buttons. In those cases, you will need to use the Selenium module to navigate while scraping. <strong>Selenium</strong> is covered <a class="reference external" href="scraping3.html">in the next chapter</a>.</p>
</div>
<div class="section" id="harvesting-multiple-urls-from-one-page">
<h2>Harvesting multiple URLs from one page<a class="headerlink" href="#harvesting-multiple-urls-from-one-page" title="Permalink to this headline">¶</a></h2>
<p>In some cases, you will want to get all the URLs from one page and save them in a file. You would then use another script to open them one by one and scrape multiple pages.</p>
<div class="literal-block-wrapper docutils container" id="id5">
<div class="code-block-caption"><span class="caption-text">../python_code_examples/scraping/harvest_urls.py</span><a class="headerlink" href="#id5" title="Permalink to this code">¶</a></div>
<div class="highlight-default notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39</pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="sd">&quot;&quot;&quot;scrape all the URLs from the article segment of a Wikipedia page</span>
<span class="sd">   and write them into a plain-text file - gets all links - even</span>
<span class="sd">   those that begin with #</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>
<span class="kn">import</span> <span class="nn">requests</span>

<span class="c1"># get the contents of one page</span>
<span class="n">start</span> <span class="o">=</span> <span class="s1">&#39;http://en.wikipedia.org/wiki/Harrison_Ford&#39;</span>
<span class="n">page</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">start</span><span class="p">)</span>
<span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">page</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="s1">&#39;html.parser&#39;</span><span class="p">)</span>

<span class="c1"># name the text file that will be created or overwritten</span>
<span class="n">filename</span> <span class="o">=</span> <span class="s1">&#39;myfile.txt&#39;</span>

<span class="k">def</span> <span class="nf">capture_urls</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">soup</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;harvest the URLs and write them to file&quot;&quot;&quot;</span>
    <span class="c1"># create and open the file for writing - note, with &#39;w&#39; this will</span>
    <span class="c1"># delete all contents of the file if it already exists</span>
    <span class="n">myfile</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span>

    <span class="c1"># get all contents of only the article</span>
    <span class="n">article</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="s1">&#39;mw-content-text&#39;</span><span class="p">)</span>

    <span class="c1"># get all &lt;a&gt; elements</span>
    <span class="n">links_list</span> <span class="o">=</span> <span class="n">article</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s1">&#39;a&#39;</span><span class="p">)</span>

    <span class="c1"># get contents of all href=&#39;&#39; attributes with a loop</span>
    <span class="k">for</span> <span class="n">link</span> <span class="ow">in</span> <span class="n">links_list</span><span class="p">:</span>
        <span class="k">if</span> <span class="s1">&#39;href&#39;</span> <span class="ow">in</span> <span class="n">link</span><span class="o">.</span><span class="n">attrs</span><span class="p">:</span>
            <span class="c1"># write one href into the text file - &#39;\n&#39; is newline</span>
            <span class="n">myfile</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">link</span><span class="o">.</span><span class="n">attrs</span><span class="p">[</span><span class="s1">&#39;href&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="c1"># close and save the file after loop ends</span>
    <span class="n">myfile</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

<span class="c1"># call the function</span>
<span class="n">capture_urls</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">soup</span><span class="p">)</span>
</pre></div>
</td></tr></table></div>
</div>
<p>It is likely that you do not want header and footer links from the page. You need to inspect the HTML and ascertain what element holds the main text. For a Wikipedia article, there’s an <code class="docutils literal notranslate"><span class="pre">id</span></code> attribute with the value <code class="docutils literal notranslate"><span class="pre">'mw-content-text'</span></code>, so that’s what we start with in line 24.</p>
<p>When we get all the <code class="docutils literal notranslate"><span class="pre">a</span></code> elements with <code class="docutils literal notranslate"><span class="pre">links_list</span> <span class="pre">=</span> <span class="pre">article.find_all('a')</span></code> (line 27), we are getting only the <code class="docutils literal notranslate"><span class="pre">a</span></code> elements that are inside the DIV element with <code class="docutils literal notranslate"><span class="pre">id='mw-content-text'</span></code> — because the variable <code class="docutils literal notranslate"><span class="pre">article</span></code> here is a Tag object containing that entire DIV.</p>
<p>Then we use a loop (lines 30–33) to look at each item in <code class="docutils literal notranslate"><span class="pre">links_list</span></code>. We check if an <code class="docutils literal notranslate"><span class="pre">href</span></code> attribute exists in the item with this line — <code class="docutils literal notranslate"><span class="pre">if</span> <span class="pre">'href'</span> <span class="pre">in</span> <span class="pre">link.attrs:</span></code> — and if there <em>is</em> an HREF, then we write the value of that HREF into the file (line 33).</p>
<p>The script above writes more than 1,400 partial URLs into a file.</p>
<p>As with the XKCD script in the previous section, here we would also concatenate a base URL with the partial URL in a scraping script:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">base_url</span> <span class="o">=</span> <span class="s1">&#39;https://en.wikipedia.org&#39;</span>
<span class="n">url</span> <span class="o">=</span> <span class="n">base_url</span> <span class="o">+</span> <span class="s1">&#39;/wiki/Blade_Runner&#39;</span>
</pre></div>
</div>
<p>It should be noted that the <em>harvest_urls.py</em> script collects a lot of partial URLs we would never want, such as internal anchors that link to parts of the same page — <code class="docutils literal notranslate"><span class="pre">#cite_note-1</span></code> and <code class="docutils literal notranslate"><span class="pre">#Early_career</span></code>, for example. To prevent those from being written to the file, we could use:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">link</span> <span class="ow">in</span> <span class="n">links_list</span><span class="p">:</span>
    <span class="k">if</span> <span class="s1">&#39;href&#39;</span> <span class="ow">in</span> <span class="n">link</span><span class="o">.</span><span class="n">attrs</span><span class="p">:</span>
        <span class="c1"># eliminate internal anchor links</span>
        <span class="k">if</span> <span class="n">link</span><span class="o">.</span><span class="n">attrs</span><span class="p">[</span><span class="s1">&#39;href&#39;</span><span class="p">][:</span><span class="mi">6</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;/wiki/&#39;</span><span class="p">:</span>
            <span class="c1"># eliminate Wikipedia photo and template links</span>
            <span class="k">if</span> <span class="n">link</span><span class="o">.</span><span class="n">attrs</span><span class="p">[</span><span class="s1">&#39;href&#39;</span><span class="p">][</span><span class="mi">6</span><span class="p">:</span><span class="mi">11</span><span class="p">]</span> <span class="o">!=</span> <span class="s1">&#39;File:&#39;</span> <span class="ow">and</span> <span class="n">link</span><span class="o">.</span><span class="n">attrs</span><span class="p">[</span><span class="s1">&#39;href&#39;</span><span class="p">][</span><span class="mi">6</span><span class="p">:</span><span class="mi">14</span><span class="p">]</span> <span class="o">!=</span> <span class="s1">&#39;Template&#39;</span><span class="p">:</span>
                <span class="c1"># write one href into the text file - \n is newline</span>
                <span class="n">myfile</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">link</span><span class="o">.</span><span class="n">attrs</span><span class="p">[</span><span class="s1">&#39;href&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>That is a bit clunky, but if you look up <a class="reference external" href="https://docs.python.org/3/tutorial/introduction.html">how to slice strings with Python</a> (Command-F search there for “Slice indices”), I think the code will make sense to you.</p>
<p>As a result, we have about 900 partial URLs instead of more than 1,400.</p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>You will <em>always</em> need to inspect the HTML of a page to figure out how best to harvest URLs from <em>that</em> particular page.</p>
</div>
</div>
<div class="section" id="scrape-multiple-pages-with-one-script">
<h2>Scrape multiple pages with one script<a class="headerlink" href="#scrape-multiple-pages-with-one-script" title="Permalink to this headline">¶</a></h2>
<p>This example shows how you can scrape multiple items from multiple pages, not using a Previous and Next button but (instead) using a collected list of partial URLs.</p>
<div class="literal-block-wrapper docutils container" id="id6">
<div class="code-block-caption"><span class="caption-text">../python_code_examples/scraping/scrape_several_pages.py</span><a class="headerlink" href="#id6" title="Permalink to this code">¶</a></div>
<div class="highlight-default notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39</pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="sd">&quot;&quot;&quot;scrape a heading and part of a paragraph from multiple pages,</span>
<span class="sd">   using a list of partial URLs</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>
<span class="kn">import</span> <span class="nn">requests</span>

<span class="c1"># links from http://en.wikipedia.org/wiki/Harrison_Ford</span>
<span class="n">link_list</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;/wiki/Melissa_Mathison&#39;</span><span class="p">,</span>
    <span class="s1">&#39;/wiki/Calista_Flockhart&#39;</span><span class="p">,</span>
    <span class="s1">&#39;/wiki/Han_Solo&#39;</span><span class="p">,</span>
    <span class="s1">&#39;/wiki/Star_Wars_Trilogy&#39;</span><span class="p">,</span>
    <span class="s1">&#39;/wiki/Indiana_Jones&#39;</span><span class="p">,</span>
    <span class="s1">&#39;/wiki/Air_Force_One_(film)&#39;</span><span class="p">,</span>
    <span class="s1">&#39;/wiki/Blade_Runner&#39;</span><span class="p">,</span>
    <span class="s1">&#39;/wiki/Carrie_Fisher&#39;</span><span class="p">]</span>

<span class="c1"># harvest data from each URL</span>
<span class="k">def</span> <span class="nf">get_info</span><span class="p">(</span><span class="n">page_url</span><span class="p">):</span>
    <span class="n">page</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;https://en.wikipedia.org&#39;</span> <span class="o">+</span> <span class="n">page_url</span><span class="p">)</span>
    <span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">page</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="s1">&#39;html.parser&#39;</span><span class="p">)</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">soup</span><span class="o">.</span><span class="n">h1</span><span class="o">.</span><span class="n">get_text</span><span class="p">())</span>
        <span class="c1"># get all paragraphs in the main article</span>
        <span class="n">paragraphs</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="s1">&#39;mw-content-text&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s1">&#39;p&#39;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">paragraphs</span><span class="p">:</span>
            <span class="c1"># skip any paragraph that has attributes</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">p</span><span class="o">.</span><span class="n">attrs</span><span class="p">:</span>
                <span class="c1"># print 280 characters from the first real paragraph on the page</span>
                <span class="nb">print</span><span class="p">(</span> <span class="n">p</span><span class="o">.</span><span class="n">text</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">280</span><span class="p">]</span> <span class="p">)</span>
                <span class="k">break</span>
        <span class="nb">print</span><span class="p">()</span> <span class="c1"># blank line</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">page_url</span> <span class="o">+</span> <span class="s1">&#39; is missing something!&#39;</span><span class="p">)</span>

<span class="c1"># call the function for each URL in the list</span>
<span class="k">for</span> <span class="n">link</span> <span class="ow">in</span> <span class="n">link_list</span><span class="p">:</span>
    <span class="n">get_info</span><span class="p">(</span><span class="n">link</span><span class="p">)</span>
</pre></div>
</td></tr></table></div>
</div>
<p>We are just <em>printing</em> the H1 and the paragraph (rather than saving them to a file or a database) for the sake of simplicity. We are using a list of only eight partial URLs for the same reason; normally you would probably have a longer list of pages to scrape.</p>
<p>The key is to write a <strong>function</strong> that scrapes all the data you want from <strong>one</strong> page (lines 19–35 above). Then <strong>call</strong> that function inside a for-loop that feeds each URL into the function (lines 38–39).</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>To create a Python list <strong>from a file</strong> such as <a class="reference external" href="https://github.com/macloo/python-adv-web-apps/blob/master/python_code_examples/scraping/myfile2.txt">myfile2.txt</a>, use the <code class="docutils literal notranslate"><span class="pre">readlines()</span></code> method. See <a class="reference external" href="working_with_files.html">Reading and Writing Files</a> for details.</p>
</div>
</div>
<div class="section" id="moving-onward">
<h2>Moving onward<a class="headerlink" href="#moving-onward" title="Permalink to this headline">¶</a></h2>
<p><a class="reference external" href="scraping3.html">In the next chapter</a>, we’ll look at how to handle more complex scraping situations with BeautifulSoup, Requests, and Selenium.</p>
<p>.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="scraping3.html" class="btn btn-neutral float-right" title="Web Scraping, Part 3" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="scraping.html" class="btn btn-neutral float-left" title="Web Scraping Intro" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020 Mindy McAdams

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>