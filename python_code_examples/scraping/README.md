# About these files

These Python scripts and files are examples of web scraping.

It is recommended that you **run the files** in the Terminal.

## Beginner

**Script:** *first_bs_test.py*

This beginner scraping script uses BeautifulSoup. It is explained line by line in [Web Scraping Intro](https://python-adv-web-apps.readthedocs.io/en/latest/scraping.html).

## Beginner (level 1.5)

**Jupyter Notebook:** *soup_practice.ipynb*

This notebook demonstrates a trial-and-error process of examining a website, step by step, to figure out what scraping code will work. You can open it for viewing only here in GitHub without running the file. To *run* the file, you’ll need BeautifulSoup, Requests, and Jupyter Notebook.

**Script:** *box_office_scraper.py*

This Python script takes the final code from the notebook *soup_practice.ipynb* and gives the final result. It includes *commented* code for writing to a CSV file.

**Text file:** *movies.csv*

This CSV file is generated by both the notebook *soup_practice.ipynb* and the script *box_office_scraper.py*.

## Beginner (level 2)

These files are explained in [Web Scraping, Part 2](https://python-adv-web-apps.readthedocs.io/en/latest/scraping2.html).

**Script:** *harvest_urls.py*
**Text file:** *myfile.txt*

Scrape all the URLs from the article segment of one Wikipedia page
   and write them into a plain-text file &mdash; gets all links &mdash; even
   those that begin with `#`.

**Script:** *harvest_urls2.py*
**Text file:** *myfile2.txt*

Scrape all the URLs from the article segment of one Wikipedia page
   and write them into a plain-text file, **omitting** all links that
   begin with `#`, `/wiki/File:`, or `/wiki/Template`.

**Script:** *scrape_several_pages.py*

Using a list of eight partial URLs, scrape a heading and part of a paragraph from multiple Wikipedia pages.

**Script:** *table_scrape.py*

Scraping a table demonstrates how to use BeautifulSoup Tag objects with `find()`, `find_all()` or `select()`.

**Script:** *xkcd_url_scrape.py*

A modified, shorter version of Sweigart’s script from chapter 12 for downloading comics from XKCD.

## Intermediate (level 3)

These files are explained in [Web Scraping, Part 3](https://python-adv-web-apps.readthedocs.io/en/latest/scraping3.html).

**Script:** *selenium_test1.py*

Read how to set up Selenium first: [Getting started with Selenium](http://bit.ly/selenium-intro).

**Script:** *selenium_test2.py*

After you’ve gotten the first Selenium script to work, try this one next.

**Script:** *selenium_test3.py*

This is the payoff: Use Selenium to click buttons on a web page to expose content that otheriwse you could not scrape.

**Script:** *headless_selenium.py*

To speed up Selenium scraping, run it “headless.” You won’t see the automated browser.

**Script:** *time_sleep.py*

Simple demo of how to insert a pause into any Python program.

.
